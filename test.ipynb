{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e850a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.prebuilt.tool_node import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "from psycopg import AsyncConnection\n",
    "from psycopg.rows import dict_row\n",
    "from app.db.crud import get_supabase_client\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Constants\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are an AI assistant that helps users manage their home security system.\n",
    "You can update the user's active monitoring events based on their requests.\n",
    "Camera descriptions (read-only, do not change):\n",
    "{cameras}\n",
    "Current active events (editable):\n",
    "{active_events}\n",
    "INSTRUCTIONS:\n",
    "1. Identify any updates to the active events list:\n",
    "    - Add new events explicitly mentioned by the user.\n",
    "    - Remove events that the user explicitly requests to stop monitoring.\n",
    "    - Modify existing events if the user provides new details.\"\"\"\n",
    "\n",
    "# Initialize clients\n",
    "supabase = get_supabase_client()\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "@tool\n",
    "def update_active_events_tool(active_events: list[str], user_id: str) -> str:\n",
    "    \"\"\"Updates the active events list and saves it to Supabase.\"\"\"\n",
    "    supabase.upsert_active_events(user_id=user_id, active_events=active_events)\n",
    "    return f\"Active events updated for user {user_id}.\"\n",
    "\n",
    "llm_with_tools = llm.bind_tools([update_active_events_tool])\n",
    "\n",
    "class AgentState(MessagesState):\n",
    "    user_id: str\n",
    "    thread_id: str\n",
    "\n",
    "def chat_node(state: AgentState):\n",
    "    cameras = supabase.get_active_cameras(user_id=state[\"user_id\"])\n",
    "    active_events = supabase.get_active_events(user_id=state[\"user_id\"])[0]['events']\n",
    "    \n",
    "    system_message = SystemMessage(\n",
    "        content=MODEL_SYSTEM_MESSAGE.format(cameras=cameras, active_events=active_events)\n",
    "    )\n",
    "    \n",
    "    messages = [system_message] + state[\"messages\"]\n",
    "    ai_reply = llm_with_tools.invoke(messages, config={\"configurable\": {\"thread_id\": state[\"thread_id\"]}})\n",
    "    \n",
    "    return {\"messages\": state[\"messages\"] + [ai_reply]}\n",
    "\n",
    "# Build and compile graph\n",
    "graph_builder = StateGraph(AgentState)\n",
    "graph_builder.add_node(\"chat\", chat_node)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[update_active_events_tool]))\n",
    "graph_builder.add_edge(START, \"chat\")\n",
    "graph_builder.add_conditional_edges(\"chat\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chat\")\n",
    "\n",
    "async def initialize_agent():\n",
    "    \"\"\"Initialize the agent with database connection.\"\"\"\n",
    "    conn = await AsyncConnection.connect(\n",
    "        os.getenv(\"SUPABASE_CONNECTION_STRING\"), \n",
    "        autocommit=True, \n",
    "        prepare_threshold=0, \n",
    "        row_factory=dict_row\n",
    "    )\n",
    "    memory = AsyncPostgresSaver(conn=conn)\n",
    "    await memory.setup()\n",
    "    return graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "async def run_chat_agent(message: str, user_id: str, thread_id  :str) -> str:\n",
    "    \"\"\"Run the chat agent and return the response.\"\"\"\n",
    "    agent = await initialize_agent()\n",
    "    \n",
    "    result = await agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(content=message)], \"user_id\": user_id, \"thread_id\": thread_id},\n",
    "        config={\"configurable\": {\"thread_id\": thread_id}}\n",
    "    )\n",
    "    \n",
    "    # Log conversation\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\"User: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"AI: {msg.content}\")\n",
    "    \n",
    "    return result[\"messages\"][-1].content if result[\"messages\"] else \"No response generated.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71cb222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hi\n",
      "AI: Hello! How can I assist you with your home security system today?\n",
      "Hello! How can I assist you with your home security system today?\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "async def main():\n",
    "    user_id = \"70c75ce4-a3af-4661-81d1-42e28ee2df9f\"\n",
    "    message = \"Hi\"\n",
    "    reply = await run_chat_agent(message, user_id, thread_id=user_id)\n",
    "    print(reply)\n",
    "\n",
    "await main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
