{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111dbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.prebuilt.tool_node import InjectedState\n",
    "from langchain_core.tools import tool\n",
    "from app.firebase.firestore import (\n",
    "    add_event,\n",
    "    get_events,\n",
    "    update_event_by_id,\n",
    "    delete_event_by_id\n",
    ")\n",
    "\n",
    "@tool\n",
    "def create_event(user_id: Annotated[str, InjectedState(\"user_id\")], event_description: str):\n",
    "    \"\"\"Create a new surveillance event to monitor.\"\"\"\n",
    "    return add_event(user_id, {\"description\": event_description})\n",
    "\n",
    "@tool\n",
    "def read_events(user_id: Annotated[str, InjectedState(\"user_id\")]):\n",
    "    \"\"\"Read all active surveillance events\"\"\"\n",
    "    return get_events(user_id)\n",
    "\n",
    "@tool\n",
    "def update_event(user_id: Annotated[str, InjectedState(\"user_id\")], event_id: str, updated_description: str):\n",
    "    \"\"\"Update a specific surveillance event with a new description.\"\"\"\n",
    "    return update_event_by_id(user_id, event_id, {\"description\": updated_description})\n",
    "\n",
    "@tool\n",
    "def delete_event(user_id: Annotated[str, InjectedState(\"user_id\")], event_id: str):\n",
    "    \"\"\"Delete an active surveillance event.\"\"\"\n",
    "    return delete_event_by_id(user_id, event_id)\n",
    "\n",
    "tools = [create_event, read_events, update_event, delete_event]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5b8481b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "from langgraph.graph import MessagesState, StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, RemoveMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing import List, Optional\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0fdd336",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"chatbot_memory.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "907e1213",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92fabf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotState(MessagesState):\n",
    "    summary: Optional[str] = None\n",
    "    user_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbe2f5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Assistant Node ---\n",
    "system_message = SystemMessage(\n",
    "    content=\"You are a home surveillance assistant. Help users manage security events. Use tools to perform actions like create, update, delete, or read events.\"\n",
    ")\n",
    "\n",
    "def assistant_node(state: ChatbotState):\n",
    "    messages = state[\"messages\"]\n",
    "    summary = state.get(\"summary\")\n",
    "    if summary:\n",
    "        context = SystemMessage(content=f\"Summary of earlier conversation: {summary}\")\n",
    "        messages = [context] + messages\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83ea7ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Summarize Node ---\n",
    "def summarize_conversation(state: ChatbotState):\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "    recent = state[\"messages\"][-2:]\n",
    "    summary_prompt = (\n",
    "        f\"This is the current summary: {summary}\\n\\n\"\n",
    "        \"Update the summary based on the new conversation above.\"\n",
    "        if summary else\n",
    "        \"Summarize the conversation above:\"\n",
    "    )\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_prompt)]\n",
    "    response = llm.invoke(messages)\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "\n",
    "    return {\n",
    "        \"summary\": response.content,\n",
    "        \"messages\": recent + delete_messages,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bcb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Condition: Decide whether to end or summarize ---\n",
    "def should_continue(state: ChatbotState):\n",
    "    if len(state[\"messages\"]) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9554f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangGraph Construction ---\n",
    "builder = StateGraph(ChatbotState)\n",
    "builder.add_node(\"assistant\", assistant_node)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "builder.add_node(\"summarize_conversation\", summarize_conversation)\n",
    "\n",
    "builder.set_entry_point(\"assistant\")\n",
    "\n",
    "# Assistant node -> tool or END\n",
    "builder.add_conditional_edges(\"assistant\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"assistant\")\n",
    "builder.add_conditional_edges(\"assistant\", should_continue)\n",
    "builder.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile with memory\n",
    "chat_graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fba6533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Public async function to use chatbot ---\n",
    "async def run_chatbot_agent(message: str, user_id: str) -> str:\n",
    "    input_msg = HumanMessage(content=message)\n",
    "    config = {\"configurable\": {\"thread_id\": user_id}}\n",
    "\n",
    "    result = await chat_graph.ainvoke({\"messages\": [input_msg],\"user_id\" : user_id}, config )\n",
    "    messages: List = result[\"messages\"]\n",
    "\n",
    "    return messages[-1].content if messages else \"No response generated.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d239ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaverfor more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m run_chatbot_agent(message=\u001b[33m\"\u001b[39m\u001b[33mHi\u001b[39m\u001b[33m\"\u001b[39m, user_id=\u001b[33m\"\u001b[39m\u001b[33m8xokvbpU0WUxMraKmWkriTtzjym2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrun_chatbot_agent\u001b[39m\u001b[34m(message, user_id)\u001b[39m\n\u001b[32m      3\u001b[39m input_msg = HumanMessage(content=message)\n\u001b[32m      4\u001b[39m config = {\u001b[33m\"\u001b[39m\u001b[33mconfigurable\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mthread_id\u001b[39m\u001b[33m\"\u001b[39m: user_id}}\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m chat_graph.ainvoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [input_msg],\u001b[33m\"\u001b[39m\u001b[33muser_id\u001b[39m\u001b[33m\"\u001b[39m : user_id}, config )\n\u001b[32m      7\u001b[39m messages: List = result[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m messages[-\u001b[32m1\u001b[39m].content \u001b[38;5;28;01mif\u001b[39;00m messages \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mNo response generated.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/eyeon-ai/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2920\u001b[39m, in \u001b[36mPregel.ainvoke\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, **kwargs)\u001b[39m\n\u001b[32m   2917\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   2918\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2920\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.astream(\n\u001b[32m   2921\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2922\u001b[39m     config,\n\u001b[32m   2923\u001b[39m     stream_mode=[\u001b[33m\"\u001b[39m\u001b[33mupdates\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   2924\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2925\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m stream_mode,\n\u001b[32m   2926\u001b[39m     print_mode=print_mode,\n\u001b[32m   2927\u001b[39m     output_keys=output_keys,\n\u001b[32m   2928\u001b[39m     interrupt_before=interrupt_before,\n\u001b[32m   2929\u001b[39m     interrupt_after=interrupt_after,\n\u001b[32m   2930\u001b[39m     **kwargs,\n\u001b[32m   2931\u001b[39m ):\n\u001b[32m   2932\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode == \u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2933\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(chunk) == \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/eyeon-ai/.venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2710\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2708\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2709\u001b[39m     config[CONF][CONFIG_KEY_CHECKPOINT_DURING] = checkpoint_during\n\u001b[32m-> \u001b[39m\u001b[32m2710\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m AsyncPregelLoop(\n\u001b[32m   2711\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2712\u001b[39m     stream=StreamProtocol(stream.put_nowait, stream_modes),\n\u001b[32m   2713\u001b[39m     config=config,\n\u001b[32m   2714\u001b[39m     store=store,\n\u001b[32m   2715\u001b[39m     cache=cache,\n\u001b[32m   2716\u001b[39m     checkpointer=checkpointer,\n\u001b[32m   2717\u001b[39m     nodes=\u001b[38;5;28mself\u001b[39m.nodes,\n\u001b[32m   2718\u001b[39m     specs=\u001b[38;5;28mself\u001b[39m.channels,\n\u001b[32m   2719\u001b[39m     output_keys=output_keys,\n\u001b[32m   2720\u001b[39m     input_keys=\u001b[38;5;28mself\u001b[39m.input_channels,\n\u001b[32m   2721\u001b[39m     stream_keys=\u001b[38;5;28mself\u001b[39m.stream_channels_asis,\n\u001b[32m   2722\u001b[39m     interrupt_before=interrupt_before_,\n\u001b[32m   2723\u001b[39m     interrupt_after=interrupt_after_,\n\u001b[32m   2724\u001b[39m     manager=run_manager,\n\u001b[32m   2725\u001b[39m     checkpoint_during=checkpoint_during\n\u001b[32m   2726\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m checkpoint_during \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2727\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m config[CONF].get(CONFIG_KEY_CHECKPOINT_DURING, \u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[32m   2728\u001b[39m     trigger_to_nodes=\u001b[38;5;28mself\u001b[39m.trigger_to_nodes,\n\u001b[32m   2729\u001b[39m     migrate_checkpoint=\u001b[38;5;28mself\u001b[39m._migrate_checkpoint,\n\u001b[32m   2730\u001b[39m     retry_policy=\u001b[38;5;28mself\u001b[39m.retry_policy,\n\u001b[32m   2731\u001b[39m     cache_policy=\u001b[38;5;28mself\u001b[39m.cache_policy,\n\u001b[32m   2732\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m loop:\n\u001b[32m   2733\u001b[39m     \u001b[38;5;66;03m# create runner\u001b[39;00m\n\u001b[32m   2734\u001b[39m     runner = PregelRunner(\n\u001b[32m   2735\u001b[39m         submit=config[CONF].get(\n\u001b[32m   2736\u001b[39m             CONFIG_KEY_RUNNER_SUBMIT, weakref.WeakMethod(loop.submit)\n\u001b[32m   (...)\u001b[39m\u001b[32m   2740\u001b[39m         node_finished=config[CONF].get(CONFIG_KEY_NODE_FINISHED),\n\u001b[32m   2741\u001b[39m     )\n\u001b[32m   2742\u001b[39m     \u001b[38;5;66;03m# enable subgraph streaming\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/eyeon-ai/.venv/lib/python3.13/site-packages/langgraph/pregel/loop.py:1177\u001b[39m, in \u001b[36mAsyncPregelLoop.__aenter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1175\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Self:\n\u001b[32m   1176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpointer:\n\u001b[32m-> \u001b[39m\u001b[32m1177\u001b[39m         saved = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checkpointer.aget_tuple(\u001b[38;5;28mself\u001b[39m.checkpoint_config)\n\u001b[32m   1178\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1179\u001b[39m         saved = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Repositories/eyeon-ai/.venv/lib/python3.13/site-packages/langgraph/checkpoint/sqlite/__init__.py:505\u001b[39m, in \u001b[36mSqliteSaver.aget_tuple\u001b[39m\u001b[34m(self, config)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34maget_tuple\u001b[39m(\u001b[38;5;28mself\u001b[39m, config: RunnableConfig) -> CheckpointTuple | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    499\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a checkpoint tuple from the database asynchronously.\u001b[39;00m\n\u001b[32m    500\u001b[39m \n\u001b[32m    501\u001b[39m \u001b[33;03m    Note:\u001b[39;00m\n\u001b[32m    502\u001b[39m \u001b[33;03m        This async method is not supported by the SqliteSaver class.\u001b[39;00m\n\u001b[32m    503\u001b[39m \u001b[33;03m        Use get_tuple() instead, or consider using [AsyncSqliteSaver][langgraph.checkpoint.sqlite.aio.AsyncSqliteSaver].\u001b[39;00m\n\u001b[32m    504\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(_AIO_ERROR_MSG)\n",
      "\u001b[31mNotImplementedError\u001b[39m: The SqliteSaver does not support async methods. Consider using AsyncSqliteSaver instead.\nfrom langgraph.checkpoint.sqlite.aio import AsyncSqliteSaver\nNote: AsyncSqliteSaver requires the aiosqlite package to use.\nInstall with:\n`pip install aiosqlite`\nSee https://langchain-ai.github.io/langgraph/reference/checkpoints/#langgraph.checkpoint.sqlite.aio.AsyncSqliteSaverfor more information."
     ]
    }
   ],
   "source": [
    "response = await run_chatbot_agent(message=\"Hi\", user_id=\"8xokvbpU0WUxMraKmWkriTtzjym2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa09ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chuck in response:\n",
    "    print(chuck,end=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
